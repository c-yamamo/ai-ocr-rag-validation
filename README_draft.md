# Operational AI Pipeline Validation with OCR × RAG × LLM
（業務文書処理を想定した・制御型 生成AIパイプライン検証）

※ 業務文書処理における生成AIパイプラインの妥当性検証（Validation）を目的とした個人検証プロジェクト

---

## 1. 概要（Overview）

本プロジェクトは、OCR・RAG・LLM を組み合わせた **業務文書処理向け生成AIパイプラインの設計・検証** を目的とした個人ポートフォリオです。

単なる精度検証や学習用途ではなく、以下の観点を重視しています。

- OCR結果の品質ばらつきを前提とした前処理設計
- LLMの判定結果を前提とした制御（再実行・停止・人手引き渡し）
- 業務システムとして「止められる・戻せる」運用視点
- 実務利用を想定したパイプラインとして成立するかの妥当性検証

---

### Why Validation?

OCR・RAG・LLM といった要素技術が動作するかを確認する PoC は、すでに一般化しています。
本検証では「AIが動くか」ではなく、**業務で使う前提条件が満たされているか** という観点で、  
生成AIパイプラインとしての妥当性（Validation）に焦点を当てています。

---

## 2. 想定ユースケース

同一の AI パイプラインを用い、性質の異なる業務文書への適用を想定したユースケースを設定しています。

---

### ユースケース1：日本語帳票（申請書）

官公庁や企業内の申請業務で用いられる申請書（PDF / 画像）を対象とします。

- 必須項目の充足可否
- 未記入・記載不備の有無
- 受付可否の一次判断

**入力形式**  
- スキャナで PDF 化された文書  
- カメラで撮影された画像  

**出力例**  
- 判定結果（OK / NG / 要確認）  
- 不足項目一覧  
- 判定理由（簡易）

---

### ユースケース2：経費精算用領収証（交通費・一般経費）

企業の経費精算業務で用いられる領収証（新幹線・タクシー・飲食等）を対象とします。

- 日付・金額・発行元の取得可否
- 経費区分（交通費・会議費 等）の一次仕分け
- 経費計上可否の一次判断

**入力形式**  
- スマートフォンで撮影された画像  
- スキャナで PDF 化された文書  

**出力例**  
- 抽出結果（項目別）  
- 判定結果（OK / NG / 要確認）  
- 判定理由

---

## 3. 全体アーキテクチャ

    [ PDF / PNG ]
          ↓
    [ OCR API ]
          ↓
    [ テキスト保存・前処理 ]
          ↓
    [ Embedding 生成 ]
          ↓
    [ Vector DB / RAG ]
          ↓
    [ LLM 評価・判断 ]
          ↓
    [ 制御ロジック ]
      ├ 再実行
      ├ 停止
      └ 人手引き渡し

※RAG は業務ルールや判定基準を参照するために利用

※ 図は後日差し替え予定

本構成では、基本はワークフロー型としつつ、OCR失敗や判定不確実性に対しては **エージェント的に処理を制御** する設計としています。

---

## 4. 技術構成（予定）

本検証では、**無料または低コストで検証可能な構成**をベースとしつつ、実務導入を想定して
**マネージドサービスへ差し替え可能な設計** としています。

---

### OCR（文書読み取り）

- マネージドOCR API を利用  
  （例：Google Cloud Vision / Azure AI Document Intelligence / Amazon Textract）
- 日本語業務文書への対応実績を重視

※ 初期検証では OSS OCR（例：PaddleOCR）によるローカル検証も行い、  
　精度・処理時間・失敗率の比較を想定しています。

---

### LLM（評価・判断）

- APIベースの LLM を利用  
  （例：OpenAI / Azure OpenAI / Google Gemini）
- 文章生成ではなく、以下の **業務判断用途** に限定
  - 項目抽出
  - カテゴリ分類
  - 入力品質チェック
  - 業務処理可否の一次判断

---

### RAG（業務ルール参照）

- 業務ルール・判定基準を外部データとして保持
- フレームワーク候補：
  - LangChain
  - LlamaIndex

業務ルールを RAG として切り出すことで、  
プロンプトの肥大化防止およびルール変更への対応を容易にしています。

---

### API / バックエンド

- FastAPI を用いて各処理を API 化
  - OCR 処理
  - LLM 判定処理
  - 制御ロジック

バッチ処理／API 両対応の構成としています。

---

### 非同期・並列処理

- Python multiprocessing による並列処理を基本構成
- 必要に応じて Celery + Redis への拡張を想定

再実行・リトライ制御を考慮した設計です。

---

### ログ・監視

- 処理単位でのログ出力（OCR結果、判定結果、処理時間）
- 失敗率・再実行回数・処理時間を品質指標として可視化
- 運用を想定した監視・ログ設計を含めた Validation を実施

---

## 5. 処理フロー概要

1. 文書（PDF / 画像）を入力
2. OCR によりテキスト化
3. 前処理（ノイズ除去・項目抽出）
4. Embedding 生成
5. Vector DB への登録・検索（RAG）
6. LLM による評価・判断
7. 判定結果に応じた制御（再実行／停止／人手引き渡し）

各ステップで品質条件を満たさない場合は、  
後段へ進まず制御ロジックにより処理を制御します。

---

## 6. 前処理・失敗ケース設計

本システムでは、**AIの出力をそのまま信頼しない設計** を前提としています。

想定している失敗ケースと対応例：

- OCR結果が空、または極端に短い  
  → 前処理条件を変更して再OCR
- 文字化けや意味不明な文章が多数含まれる  
  → 再処理または停止
- 業務上必須となる項目が取得できない  
  → 人手確認へ引き渡し

---

## 7. LLMによる評価・判断

LLMは文章生成ではなく、**判断装置** として利用します。

- 文書として十分な情報量があるか
- 業務処理に耐えうる内容か
- 再処理・人手確認が必要か

判定結果は Yes / No 形式で返却し、制御ロジックに連携します。

---

## 8. 制御ロジック設計

- 再実行回数の上限設定
- 無限ループ防止
- 人手引き渡しフラグの出力

インフラ運用経験を活かし、  
生成AIパイプラインを **「止められるシステム」** として設計しています。

---

## 9. Author

- GitHub: c-yamamo  
- Role: Infrastructure Engineer / AI Pipeline Validation
